# -*- coding: utf-8 -*-
"""Migration-ETL-form_response.v1.1.0.0-40000.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n8HjTIufu4oRXlQu6d1cx-QO9xVZU08T
"""

import os
import re
import json
import pandas as pd
import numpy as np
from pandas import json_normalize
from google.cloud import storage
from tqdm import tqdm

import logs.logging_conf, logging
logger = logging.getLogger("gcs_to_openrefine.py")

"""## Mount Google Drive (if using service account keys)"""

#from google.colab import drive
#drive.mount('/content/drive')

"""## Set Env Variables"""

ENVIRONMENT = 'production'
#ENVIRONMENT = 'development'

service_account_key = "prod-gcs-colab@reach52-dataops.iam.gserviceaccount.com.json"
project_id = 'reach52-dataops'
country = "philippines"
stg_bucket_name = f"stage-r52_dhs-{country}"
fnl_bucket_name = f"final-r52_dhs-{country}"

os.environ['GOOGLE_APPLICATION_CREDENTIALS']=f"./secrets/{service_account_key}"
gcs_colab_secret = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')

#gcloud config set project {project_id}

"""## Authenticate using service account

"""

from oauth2client.service_account import ServiceAccountCredentials

scope = ['https://www.googleapis.com/auth/analytics',
        'https://www.googleapis.com/auth/analytics.edit']
creds = ServiceAccountCredentials.from_json_keyfile_name(gcs_colab_secret, scope)

#client = gspread.authorize(creds)

"""## Extract

### Iterate GCS file in Staging Directory
"""

def list_staging_files(bucket_name, prefix_url):
  storage_client = storage.Client()

  #blobs = storage_client.list_blobs(bucket_name, prefix="_Stage/form-response/")
  blobs = storage_client.list_blobs(bucket_name, prefix=prefix_url)
  #blob_list = list(blobs)
  blob_list = []

  for blob in blobs:
    blob_list.append(blob.name)

  #return blob_list[1:]
  return blob_list[1:]

def main():
  stg_collection_type = 'form-response'
  fnl_collection_type = 'form-response'
  stg_folder_type = '_Stage'
  fnl_folder_type = '_Final'

  content_data_type = 'question' #form-response
  main_reference_key = 'questionCode' #form-response

  prefix = f"{stg_collection_type}" #PROD

  staging_files = list_staging_files(stg_bucket_name, prefix)
  print(staging_files)


def mainx():

  stg_collection_type = 'form-response'
  fnl_collection_type = 'form-response'
  stg_folder_type = '_Stage'
  fnl_folder_type = '_Final'

  content_data_type = 'question' #form-response
  main_reference_key = 'questionCode' #form-response

  #content_data_type = 'tag' #form-question
  #main_reference_key = '$oid' #form-question

  #prefix = f"{stg_folder_type}/{stg_collection_type}" #DEV
  prefix = f"{stg_collection_type}" #PROD

  #staging_files = list_staging_files(bucket_name, prefix)
  staging_files = list_staging_files(stg_bucket_name, prefix)
  # staging_files = [
      #'_Stage/form-response/IND/form_response.reach52MasterLiveIND1.android.ap-south1.2022-03-28.02:03:25.003e1e13-3870-4012-b2c1-ba89a7c16046.json',
      #'_Stage/form-response/IND/form_response.reach52MasterLiveIND1.android.ap-south1.2022-03-28.02:03:25.00657ee2-9861-4091-9164-766d61f6752c.json'
      # 'stage-r52_dhs-philippines/form-response/form_response.reach52MasterLiveIND1.android.ap-south1.2022-00-06.03:00:00.2197fecc-4faf-42b3-8752-148338e1914a.json',
      # 'stage-r52_dhs-philippines/form-response/form_response.reach52MasterLiveIND1.android.ap-south1.2022-00-06.03:00:00.20865411-8e25-4233-b29e-69eb57eaae3d.json'
      # ]

  #for indx, staging_file in enumerate(staging_files[1:2]):
  #for indx, staging_file in enumerate(staging_files):
  #  for indx, staging_file in enumerate(staging_files[0:10000]):
  #0, 5490 (5490), 4168 (9658), 
  #for indx, staging_file in enumerate(staging_files[9658:40000]): 
  for indx, staging_file in enumerate(staging_files): 
    print(f'processing...{indx}/{len(staging_files)}')
    print(f'staging_file... ', staging_file)
    
    file_name = extract_file_name(staging_file)
    
    file_id = extract_file_id(staging_file)
    
    data_df = extract_gcs_blob(stg_bucket_name, staging_file)

    eav_df = build_eav_model(data_df, file_id)

    content_df = eav_df[['question_key','question_value']][eav_df['data_type'] == content_data_type ]

    content_reference_df = extract_reference_field(content_df)

    main_reference_df = content_reference_df[content_reference_df['question_key'] ==  main_reference_key ]

    reference_df = link_reference(content_reference_df, main_reference_df)

    merged_df = pd.merge(eav_df, reference_df, on='question_order', how='outer')

    final_df = final_cleanup(merged_df, main_reference_key)
    
    #upload_gcs_blob(final_df, fnl_folder_type, fnl_collection_type, file_name) #DEV
    upload_gcs_blob(fnl_bucket_name, final_df, fnl_folder_type, fnl_collection_type, file_name) #PROD

    move_blob(stg_bucket_name, staging_file, stg_bucket_name, f"{stg_collection_type}/_archived/{file_name}.json")
    print('=============')

if __name__ == "__main__":
  main()

